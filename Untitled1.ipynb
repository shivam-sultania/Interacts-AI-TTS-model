{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPimseod3/c3bCY7TZtK3vv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivam-sultania/Interacts-AI-TTS-model/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sZny9NbNIj4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46598c9b-36c8-4d4d-ca2d-7613980de1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (13.1)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n",
            "fatal: destination path 'vits' already exists and is not an empty directory.\n",
            "/content/vits\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchaudio librosa numpy websockets ffmpeg-python\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "!git clone https://github.com/jaywalnut310/vits.git\n",
        "%cd vits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/AI4Bharat_dataset\"  # Adjust this path to dataset's location in Google Drive\n",
        "CHECKPOINT_PATH = \"/content/drive/MyDrive/checkpoints_vits\"  # Directory to save model checkpoints\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5PZn97jOB9f",
        "outputId": "dcf2041a-c6a3-47be-8337-504dfbf33721"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prepare_dataset():\n",
        "    transcripts_file = f\"{DATASET_PATH}/transcript.txt\"\n",
        "    data = []\n",
        "\n",
        "    # Read and clean data\n",
        "    with open(transcripts_file, \"r\") as f:\n",
        "        current_line = \"\"\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if \"|\" in line:\n",
        "                if current_line:\n",
        "                    data.append(current_line.split(\"|\", 1))  # Spliting only once to handle long texts\n",
        "                current_line = line\n",
        "            else:\n",
        "                current_line += \" \" + line\n",
        "\n",
        "        if current_line:\n",
        "            data.append(current_line.split(\"|\", 1))\n",
        "\n",
        "    data = [entry for entry in data if len(entry) == 2]\n",
        "\n",
        "    # Spliting data into 80/10/10 for train/val/test\n",
        "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "    val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
        "\n",
        "    # Save split files\n",
        "    for split_name, split_data in zip([\"train\", \"val\", \"test\"], [train_data, val_data, test_data]):\n",
        "        with open(f\"{DATASET_PATH}/{split_name}/metadata.txt\", \"w\") as f:\n",
        "            for filename, text in split_data:\n",
        "                f.write(f\"{filename}|{text}\\n\")\n",
        "\n",
        "prepare_dataset()"
      ],
      "metadata": {
        "id": "9NuT7tCiObvD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "    \"sampling_rate\": 16000,\n",
        "    \"batch_size\": 16,\n",
        "    \"epochs\": 1000,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"data\": {\n",
        "        \"training_files\": f\"{DATASET_PATH}/train/metadata.txt\",\n",
        "        \"validation_files\": f\"{DATASET_PATH}/val/metadata.txt\",\n",
        "        \"sampling_rate\": 16000,\n",
        "        \"n_mel_channels\": 80,\n",
        "        \"n_symbols\": 40,\n",
        "        \"text_cleaners\": [\"basic_cleaners\"]\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"hidden_channels\": 192,\n",
        "        \"n_flow\": 4,\n",
        "        \"n_group\": 8,\n",
        "        \"n_layers\": 3\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save config to JSON\n",
        "with open(\"config.json\", \"w\") as f:\n",
        "    json.dump(config, f, indent=2)"
      ],
      "metadata": {
        "id": "hiAMa-SUPF-K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/vits\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "id": "N9ohvKvCczxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y build-essential\n",
        "!pip install Cython\n",
        "!pip install numpy\n",
        "!git clone https://github.com/jaywalnut310/vits.git\n",
        "%cd vits\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install unidecode\n",
        "\n",
        "%cd monotonic_align\n",
        "!python setup.py build_ext --inplace\n",
        "%cd ..\n",
        "\n",
        "from setuptools import setup\n",
        "from Cython.Build import cythonize\n",
        "import numpy\n",
        "\n",
        "setup(\n",
        "    name='monotonic_align',\n",
        "    ext_modules=cythonize(\"/content/vits/monotonic_align/core.pyx\"),\n",
        "    include_dirs=[numpy.get_include()],\n",
        "    script_args=[\"build_ext\", \"--build-lib\", \"/content/vits/monotonic_align\"]\n",
        ")\n",
        "import sys\n",
        "sys.path.append('/content/vits')\n",
        "sys.path.append('/content/vits/monotonic_align')\n",
        "\n",
        "%cd /content/vits/monotonic_align\n",
        "\n",
        "!mkdir -p build\n",
        "# List contents to ensure the .so file exist\n",
        "!python setup.py build_ext --inplace\n",
        "!ls /content/vits/monotonic_align\n",
        "# from Cython.Build import cythonize\n",
        "# import numpy\n",
        "# import pyximport\n",
        "from monotonic_align.core import maximum_path_c\n",
        "print(\"Import successful!\")\n",
        "\n",
        "\n",
        "# from setuptools import setup, Extension\n",
        "# from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n",
        "\n",
        "# !nvcc --version\n",
        "# from torch.utils.cpp_extension import load\n",
        "# import os\n",
        "\n",
        "# # Compile the extension\n",
        "# core = load(name=\"core\",\n",
        "#             sources=[\"/content/vits/monotonic_align/core.cpp\", \"/content/vits/monotonic_align/core.cu\"],\n",
        "#             verbose=True)\n",
        "\n",
        "# !ls\n",
        "# import sys\n",
        "# sys.path.append('/content/vits/vits/monotonic_align')\n",
        "\n",
        "# # Now try importing the required modules\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "# # Adjust import based on the location of maximum_path_c"
      ],
      "metadata": {
        "id": "gofEA4LbfSL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/vits')\n",
        "\n",
        "import json\n",
        "from torch.utils.data import DataLoader\n",
        "from vits.vits import VITS\n",
        "from vits.trainer import Trainer\n",
        "from vits.dataset import TextAudioLoader\n",
        "\n",
        "def train_vits():\n",
        "    with open(\"config.json\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    train_dataset = TextAudioLoader(config[\"data\"][\"training_files\"], config)\n",
        "    val_dataset = TextAudioLoader(config[\"data\"][\"validation_files\"], config)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "    model = VITS(config)\n",
        "    trainer = Trainer(model=model, train_loader=train_loader, val_loader=val_loader, config=config)\n",
        "\n",
        "    trainer.train(epochs=config[\"epochs\"])\n",
        "\n",
        "train_vits()\n"
      ],
      "metadata": {
        "id": "NYMNzVq0PRKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "def load_model(checkpoint_path):\n",
        "    model = vits.load_from_checkpoint(checkpoint_path)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def synthesize_text(model, text, config):\n",
        "    text_sequence = model.text_to_sequence(text, config[\"data\"][\"text_cleaners\"])\n",
        "    with torch.no_grad():\n",
        "        audio = model.infer(text_sequence)\n",
        "    return audio\n",
        "\n",
        "checkpoint_path = f\"{CHECKPOINT_PATH}/last_checkpoint.pth\"\n",
        "\n",
        "model = load_model(checkpoint_path)\n",
        "sample_text = \"Sample text for synthesis\"\n",
        "output_audio = synthesize_text(model, sample_text, config)\n",
        "\n",
        "# Save generated audio as a WAV file\n",
        "sf.write(\"output.wav\", output_audio, config[\"sampling_rate\"])\n"
      ],
      "metadata": {
        "id": "YGwAX-sXPWjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def save_checkpoint(epoch):\n",
        "    checkpoint_name = f\"checkpoint_epoch_{epoch}.pth\"\n",
        "    model_checkpoint = f\"{CHECKPOINT_PATH}/{checkpoint_name}\"\n",
        "    shutil.copy(\"last_checkpoint.pth\", model_checkpoint)\n",
        "\n",
        "save_checkpoint(100)\n"
      ],
      "metadata": {
        "id": "YwC-w5CJPZJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}